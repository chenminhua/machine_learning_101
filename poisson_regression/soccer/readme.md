# 线性回归存在的问题

线性回归将因变量的误差定义为正态分布其实也是过于理想的假设。
比如当因变量是离散输出时，使用正态分布假设的建模效果自然会大打折扣。在一场足球比赛中，某只球队进球数目超过 8 个的概率微乎其微。因而在预测某队的进球数时，用正态分布对分布在 01234567 这些离散数值上的因变量进行建模就缺乏合理性，泊松分布才是更好的选择。

可不巧的是，正态分布恰恰是狭义线性模型的核心成分，它是联结最小均方误差和最大似然估计的纽带。在求解时，狭义的线性模型建立在最小均方误差的意义上，其解析解可由普通最小二乘法求得，求解时的一个基本前提是是回归结果的误差服从正态分布。

误差的正态分布意味着因变量既可以增加也减少，其增加或者减少的范围虽然不存在上限，却以较大的概率出现在一个较小的区间内。如果按照前文的方式改造狭义线性模型的话，噪声的正态性质就不能得以保持，简洁明晰的解析解也会不再适用。因此，要拓展线性模型的应用范围，新的数学工具不可或缺。

# 广义线性模型

广义线性模型（generalized linear model）就是这样的数学工具。在广义线性模型中，因变量可以满足任意形式的概率分布，它与自变量的线性组合之间的关系由联系函数定义。逻辑回归就是广义线性模型的一个实例，它的因变量是二进制的输出，联系函数则是对数几率函数。这个实例体现出了在一般意义上，广义线性模型要满足一些共性的条件。

**指数分布族、联系函数和线性关系共同构成了广义线性模型的三大要素。**

广义线性模型从模型解释性和变量分布特性上对普通线性模型做了推广；
广义线性模型假定因变量服从指数分布族中的概率分布，这代表了模型中的随机成分；
广义线性模型中的自变量和因变量依然由线性系数决定，这代表了模型中的系统成分；
联系函数建立系统成分和随机成分的关系，将指数分布的自然参数表示为自变量的线性组合。

# 例子

如果以新科英超冠军曼城队作为数据采集对象，统计曼城队在 2017-18 英超赛季所有主场比赛中的进球数，得到的就是包含 19 个样本的数据集。

这个数据集的因变量是符合泊松分布的进球数目，自变量则考虑了一系列和进攻有关的数据，包括射门次数（shots）、射正次数（shots on target）、传球成功率（pass accuracy）、争顶成功率（aerial dual success）、过人次数（dribbles won）和控球比率（possession）这么几个属性。用这些属性对进球数进行泊松回归的拟合，从结果中可以看出，泊松回归使用的联系函数是自然对数函数。在统计学的显著性上，射正次数、传球成功率和控球比率三个属性对进球数有明显的影响，另外三个属性对进球数基本没有贡献。

利用这三个强相关的属性来拟合泊松回归，可以看到，基于强相关属性计算出的线性系数基本没有变化。由于泊松回归使用的联系函数是对数函数，所以线性回归分析出来的结果是因变量期望值的对数，要解释计算出的参数就得对它们做个指数运算。exp(x1)=1.18 可以粗略地解释为当其他条件不变时，每多一脚命中门框的射门都能让进球数变成原来的 1.18 倍。但整体来看，广义线性模型在增强表达能力时，付出的是可解释性的代价。

一般线性模型中的因变量必须是连续分布的，回归结果的误差服从正态分布，联系函数是因变量本身。而广义线性模型中的因变量可以是非连续分布，回归结果的误差如文中所述可以是非正态分布，联系函数可以是自变量线性组合的函数。

引入非线性的方式既可以是联系函数，也可以是基扩展，多项式回归就是基扩展的具体实现，构造时最主要的任务就是确定多项式阶数，这个超参数一般要通过交叉验证确定最优值。
