{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 过拟合就是模型过于复杂以至于削弱了它的泛化性能。\n",
    "\n",
    "### 正则化（regularization）抑制过拟合\n",
    "通过动态调整估计参数的取值来降低模型的复杂度，以偏差的增加为代价来换取方差的下降。这是因为当一些参数足够小时，它们对应的属性对输出结果的贡献就会微乎其微，这在实质上去除了非相关属性的影响。\n",
    "\n",
    "在线性回归里，最常见的正则化方式就是在损失函数（loss function）中添加正则化项（regularizer）（往往是待估计参数的p范数）。将均方误差和参数的范数之和作为一个整体来进行约束优化，相当于额外添加了一重关于参数的限制条件，**避免大量参数同时出现较大的取值**。\n",
    "由于正则化的作用通常是让参数估计值的幅度下降，因此在统计学中它也被称为**系数收缩方法（shrinkage method）**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当正则化项为1-范数时，就是岭回归。\n",
    "当正则化项为2-范数的平方时，就是lasso。\n",
    "elastic net则是两者的折中方案，为1范数和2范数的线性组合。\n",
    "\n",
    "**岭回归的作用是衰减不同属性的权重，让所有属性一起向圆心收拢；\n",
    "lasso则直接将某些属性的权重降为0,完成属性过滤的任务。**\n",
    "\n",
    "**弹性网络则结合了两者的优点，它不会轻易地将某些属性抛弃，从而使全部信息得以保留，但对不重要的特征也会毫不手软地大幅削减其权重系数。**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 贝叶斯角度的观察\n",
    "**正则化就是引入关于参数的先验信息。**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
