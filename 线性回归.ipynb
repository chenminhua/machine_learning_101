{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.read_table('./regression.csv')\n",
    "point = stats.iloc[:,4] / 38\n",
    "rating = stats.iloc[:,5]\n",
    "positional_rating = stats.iloc[:,[0,1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      GK    DF    MF    FW  Points  Ratings\n",
      "0   6.68  7.10  7.61  7.63   100.0     7.15\n",
      "1   6.83  7.20  7.17  6.97    81.0     6.98\n",
      "2   6.74  7.08  6.98  7.33    77.0     6.95\n",
      "3   6.70  7.01  7.01  7.45    75.0     6.99\n",
      "4   6.63  6.97  7.05  7.21    70.0     6.94\n",
      "5   6.75  7.10  7.18  7.10    63.0     6.92\n",
      "6   6.93  7.05  6.72  6.65    54.0     6.78\n",
      "7   6.63  6.85  6.64  6.81    49.0     6.67\n",
      "8   6.61  6.77  6.93  6.95    47.0     6.74\n",
      "9   6.75  6.91  6.75  6.73    44.0     6.72\n",
      "10  6.70  6.87  6.91  7.13    44.0     6.84\n",
      "11  6.52  6.77  6.69  6.71    44.0     6.65\n",
      "12  6.53  6.76  6.82  6.95    42.0     6.72\n",
      "13  6.54  6.78  6.76  6.63    41.0     6.66\n",
      "14  6.74  6.87  6.78  6.67    40.0     6.69\n",
      "15  6.57  6.74  6.69  6.55    37.0     6.61\n",
      "16  6.52  6.69  6.80  6.58    36.0     6.67\n",
      "17  6.89  6.71  6.53  6.63    33.0     6.59\n",
      "18  6.76  6.85  6.73  6.77    33.0     6.70\n",
      "19  6.50  6.80  6.68  6.66    31.0     6.63\n"
     ]
    }
   ],
   "source": [
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Points   R-squared:                       0.905\n",
      "Model:                            OLS   Adj. R-squared:                  0.900\n",
      "Method:                 Least Squares   F-statistic:                     172.2\n",
      "Date:                Sun, 10 Mar 2019   Prob (F-statistic):           1.18e-10\n",
      "Time:                        18:52:53   Log-Likelihood:                 9.3960\n",
      "No. Observations:                  20   AIC:                            -14.79\n",
      "Df Residuals:                      18   BIC:                            -12.80\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -19.4345      1.586    -12.256      0.000     -22.766     -16.103\n",
      "Ratings        3.0685      0.234     13.123      0.000       2.577       3.560\n",
      "==============================================================================\n",
      "Omnibus:                        3.586   Durbin-Watson:                   2.238\n",
      "Prob(Omnibus):                  0.166   Jarque-Bera (JB):                1.886\n",
      "Skew:                          -0.713   Prob(JB):                        0.389\n",
      "Kurtosis:                       3.481   Cond. No.                         308.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# 在使用 StatsModels 拟合模型时，首先要用 add_constant 函数在每个输入数据的后面添加一个 1，借此把常数项纳入模型之中；\n",
    "rating_add = sm.add_constant(rating)\n",
    "# 接下来就可以调用 OLS，也就是普通最小二乘法（ordinary least squares）作为拟合对象，计算线性模型的参数；\n",
    "# 最后使用 fit 函数获取拟合结果。要查看拟合模型的统计特性，只需打印出模型的 summary\n",
    "est_simple = sm.OLS(point,rating_add).fit()\n",
    "print(est_simple.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coef 表示的是参数的估计值，也就是通过最小二乘计算出的权重系数。\n",
    "拟合结果 y = 3.0685x - 19.4345，这说明如果所有球员共同努力将平均评分拉高 0.1 的话，球队在每场比赛中就能平均多得 0.306 分。\n",
    "\n",
    "std err 表示的是参数估计的标准误（standard error），虽然最小二乘得到的是无偏估计量，意味着估计结果中不存在系统误差，但每一个特定的估计值结果依然会在真实值的附近波动，标准误度量的就是估计值偏离真实值的平均程度。\n",
    "\n",
    "最后两列 [0.025 0.975] 给出了 95% 置信区间：每个参数真实值落在这个区间内的可能性是 95%。对于线性回归而言，置信下界和上界分别是估计值减去和加上二倍的标准误。\n",
    "\n",
    "置信区间告诉我们，平均评分拉高 0.1 并不意味着球队每场一定能多得 0.306 分，但多得的分数基本在 0.258 到 0.356 之间。如果用 2016-17 赛季的数据作为训练数据的话，这个数据的计算结果就变成了 0.33——也落在置信区间之内，这也验证的估计结果的波动性。\n",
    "\n",
    "中间两列中的 t 和 P>|t|都是统计学中的关键指标，它们评估的是拟合结果的统计学意义。t 代表 $t$ 统计量（$t$-statistic），表示了参数的估计值和原始假设值之间的偏离程度。在线性回归中通常会假设待拟合的参数值为 0，此时的 $t$ 统计量就等于估计值除以标准误。**当数据中的噪声满足正态分布时，$t$ 统计量就满足 $t$ 分布，其绝对值越大意味着参数等于 0 的可能性越小，拟合的结果也就越可信**。\n",
    "\n",
    "P>|t|表示的则是统计学中争议最大的指标——$p$ 值。$p$ 值（$p$-value）是在当原假设为真时，数据等于观测值或比观测值更为极端的概率。简单地说，$p$ 值表示的是数据与一个给定模型不匹配的程度，$p$ 值越小，说明数据和原假设的模型越不匹配，也就和计算出的模型越匹配。在这个例子里，原假设认为待估计的参数等于 0，而接近于 0 的 $p$ 值就意味着计算出的参数值得信任。\n",
    "\n",
    "看完第二排再来看第一排，也就是对模型拟合数据的程度的评价，重要的指标在右侧一列。R-squared 表示的是 $R ^ 2$ 统计量，也叫作决定系数（coefficient of determination），这个取值在 [0, 1] 之间的数量表示的是输出的变化中能被输入的变化所解释的部分所占的比例。在这个例子里，$R ^ 2 = 0.905$ 意味着回归模型能够通过 $x$ 的变化解释大约 91% 的 $y$ 的变化，这表明回归模型具有良好的准确性，回归后依然不能解释的 9% 就来源于噪声。\n",
    "\n",
    "$R ^ 2$ 统计量具有单调递增的特性，即使在模型中再添加一些和输出无关的属性，计算出来的 $R ^ 2$ 也不会下降。Adj. R-squared 就是校正版的 $R ^ 2$ 统计量。当模型中增加的变量没有统计学意义时，多余的不相关属性会使校正决定系数下降。校正决定系数体现出的是正则化的思想，它在数值上小于未校正的 $R ^ 2$ 统计量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Points   R-squared:                       0.902\n",
      "Model:                            OLS   Adj. R-squared:                  0.876\n",
      "Method:                 Least Squares   F-statistic:                     34.57\n",
      "Date:                Sun, 10 Mar 2019   Prob (F-statistic):           2.09e-07\n",
      "Time:                        18:57:19   Log-Likelihood:                 9.0610\n",
      "No. Observations:                  20   AIC:                            -8.122\n",
      "Df Residuals:                      15   BIC:                            -3.143\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -15.5306      2.366     -6.563      0.000     -20.574     -10.487\n",
      "GK            -0.2112      0.454     -0.466      0.648      -1.178       0.756\n",
      "DF             1.5722      0.545      2.885      0.011       0.411       2.734\n",
      "MF             0.5510      0.354      1.556      0.141      -0.204       1.306\n",
      "FW             0.5337      0.237      2.249      0.040       0.028       1.040\n",
      "==============================================================================\n",
      "Omnibus:                        3.397   Durbin-Watson:                   1.989\n",
      "Prob(Omnibus):                  0.183   Jarque-Bera (JB):                2.804\n",
      "Skew:                          -0.861   Prob(JB):                        0.246\n",
      "Kurtosis:                       2.369   Cond. No.                         823.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "positional_rating_add = sm.add_constant(positional_rating)\n",
    "est_multi = sm.OLS(point,positional_rating_add).fit()\n",
    "print(est_multi.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个实例中，多元回归的属性，也就是自变量被设置为每队每个位置上出场时间较多的球员的赛季平均评分的均值，所有选中球员的出场时间都在 1000 分钟以上。\n",
    "\n",
    "利用 OLS 模型可以得到多元回归的结果，可如果对结果加以分析，就会发现一个有趣的现象：一方面，多元模型的校正决定系数是 0.876，意味着所有位置评分共同解释了输出结果的大部分变化，这也可以从预测值与真实值的散点图上观察出来；可另一方面，只有后卫评分和前锋评分的 $p$ 值低于 0.05，似乎球队的战绩只取决于这两个位置的表现。\n",
    "\n",
    "看起来校正决定系数和 $p$ 值给出了自相矛盾的解释，这时就需要观察另外一个重要的指标：$F$ 统计量。\n",
    "\n",
    "F 统计量主要应用在多元回归中，它检验的原假设是所有待估计的参数都等于 0，这意味着只要有一个参数不等于 0，原假设就被推翻。$F$ 统计量越大意味着原假设成立的概率越低，理想的 $F$ 值应该在百千量级。可在上面的多元回归中，$F$ 统计量仅为 34.57，这就支持了 $p$ 值的结论：估计出的参数的统计学意义并不明显。\n",
    "\n",
    "英超数据集在统计上的非显著性可能源自过小的样本数导致的过拟合，也可能源自不同属性之间的共线性（collinearity）。可在更广泛的意义上，它揭示的却是多元线性回归无法回避的一个本质问题：**模型虽然具有足够的精确性，却缺乏关于精确性的合理解释**。\n",
    "\n",
    "假定数据共有 10 个属性，如果只保留 10 个属性中的 5 个用于拟合的话，肯定会有不止一个 5 元属性组能够得到彼此接近的优良性能，可对不同 5 元组的解读方式却会大相径庭。这种现象，就是统计学家莱奥·布雷曼口中的“罗生门”（Rashomon）。布雷曼用这个词来描述最优模型的多重性，以及由此造成的统计建模的艰难处境：当不同的多元线性模型性能相近，却公说公有理婆说婆有理时，到底应该如何选择？\n",
    "\n",
    "将“罗生门”深挖一步，就是机器学习和统计学在认识论上的差异：统计学讲究的是“知其然，知其所以然”，它不仅要找出数据之间的关联性，还要挖出背后的因果性，给计算出的结果赋予令人信服的解释才是统计的核心。相比之下，机器学习只看重结果，只要模型能够对未知数据做出精确的预测，那这个模型能不能讲得清楚根本不是事儿。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
